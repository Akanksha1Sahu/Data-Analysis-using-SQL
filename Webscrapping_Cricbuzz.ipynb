{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Steps for extracting the dataÂ¶\n",
        "Send an HTTP request to the web page using the requests library.\n",
        "Parse the HTML content of the web page using BeautifulSoup.\n",
        "Identify the HTML tags that contain the data you want to extract.\n",
        "Use BeautifulSoup methods to extract the data from the HTML tags.\n",
        "Print the extracted data\n",
        "\n",
        "\n",
        "\n",
        "in simple words, parsing refers to the process of analyzing a string of text or a data structure, usually following a set of rules or grammar, to understand its structure and meaning"
      ],
      "metadata": {
        "id": "wZPrLVfVQMdj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsWDaH_z1MyF",
        "outputId": "b3cd85ea-8f6a-40d5-d580-6c95c823171e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio files extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "import requests #import or downlaod  website\n",
        "from bs4 import BeautifulSoup # scrap #structured into format\n",
        "import os # creating folder for images\n",
        "# Define the URL of the Cricbuzz website\n",
        "url = \"https://www.cricbuzz.com/\"  # Replace with the actual website URL\n",
        "\n",
        "# Send an HTTP GET request to the website\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Create a directory to store the downloaded audio files\n",
        "    os.makedirs(\"cricbuzz_audio_files\", exist_ok=True)\n",
        "\n",
        "    # Find links or elements that may lead to audio files\n",
        "    audio_elements = soup.find_all('audio')  # Adjust based on the structure of the website\n",
        "\n",
        "    for audio in audio_elements:\n",
        "        # Extract the audio source URL\n",
        "        audio_url = audio.get('src')\n",
        "\n",
        "        if audio_url:\n",
        "            # Download the audio file\n",
        "            audio_response = requests.get(audio_url)\n",
        "            if audio_response.status_code == 200:\n",
        "                audio_filename = os.path.basename(audio_url)\n",
        "                audio_path = os.path.join(\"cricbuzz_audio_files\", audio_filename)\n",
        "                with open(audio_path, 'wb') as audio_file:\n",
        "                    audio_file.write(audio_response.content)\n",
        "                print(f\"Downloaded: {audio_path}\")\n",
        "\n",
        "    print(\"Audio files extracted successfully.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the Cricbuzz web page (status code: {}).\".format(response.status_code))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "from urllib.parse import urljoin  # Import urljoin to handle relative URLs\n",
        "\n",
        "# Define the URL of the Cricbuzz website\n",
        "url = \"https://www.cricbuzz.com/\"  # Replace with the actual website URL\n",
        "\n",
        "# Send an HTTP GET request to the website\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Create a directory to store the downloaded images\n",
        "    os.makedirs(\"cricbuzz_images2\", exist_ok=True)\n",
        "\n",
        "    # Find all image tags and download images\n",
        "    img_tags = soup.find_all('img')\n",
        "    for img in img_tags:\n",
        "        img_url = img.get('src')\n",
        "        if img_url:\n",
        "            # Check if the URL is valid and contains a schema (http:// or https://)\n",
        "            if img_url.startswith('http://') or img_url.startswith('https://'):\n",
        "                img_response = requests.get(img_url)\n",
        "                if img_response.status_code == 200:\n",
        "                    img_filename = os.path.basename(img_url)\n",
        "                    img_path = os.path.join(\"cricbuzz_images2\", img_filename)\n",
        "                    with open(img_path, 'wb') as img_file:\n",
        "                        img_file.write(img_response.content)\n",
        "                    print(f\"Downloaded1: {img_path}\")\n",
        "            else:\n",
        "                # Handle relative URLs by joining with the base URL\n",
        "                full_img_url = urljoin(url, img_url)\n",
        "                img_response = requests.get(full_img_url)\n",
        "                if img_response.status_code == 200:\n",
        "                    img_filename = os.path.basename(full_img_url)\n",
        "                    img_path = os.path.join(\"cricbuzz_images2\", img_filename)\n",
        "                    with open(img_path, 'wb') as img_file:\n",
        "                        img_file.write(img_response.content)\n",
        "                    print(f\"Downloaded2: {img_path}\")\n",
        "\n",
        "    print(\"Images extracted successfully.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the Cricbuzz web page (status code: {}).\".format(response.status_code))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33nlXhln6vSx",
        "outputId": "7f8ecc22-b95d-4c84-96cc-594fed61ae3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded2: cricbuzz_images2/cb_logo.svg\n",
            "Downloaded2: cricbuzz_images2/sri-lanka.jpg\n",
            "Downloaded2: cricbuzz_images2/australia.jpg\n",
            "Downloaded2: cricbuzz_images2/south-africa.jpg\n",
            "Downloaded2: cricbuzz_images2/netherlands.jpg\n",
            "Downloaded2: cricbuzz_images2/afghanistan.jpg\n",
            "Downloaded2: cricbuzz_images2/england.jpg\n",
            "Downloaded2: cricbuzz_images2/haryana.jpg\n",
            "Downloaded2: cricbuzz_images2/mumbai.jpg\n",
            "Downloaded2: cricbuzz_images2/baroda.jpg\n",
            "Downloaded2: cricbuzz_images2/jammu-and-kashmir.jpg\n",
            "Downloaded2: cricbuzz_images2/victoria.jpg\n",
            "Downloaded2: cricbuzz_images2/queensland.jpg\n",
            "Downloaded2: cricbuzz_images2/cricket-officially-confirmed-f.jpg\n",
            "Downloaded2: cricbuzz_images2/afghanistan-get-their-seminal.jpg\n",
            "Downloaded2: cricbuzz_images2/the-admin-rot-that-south-afric.jpg\n",
            "Downloaded2: cricbuzz_images2/rohit-sharma-directors-cut.jpg\n",
            "Downloaded2: cricbuzz_images2/williamson-sustains-undisplac.jpg\n",
            "Downloaded2: cricbuzz_images2/south-africa-bides-time-appea.jpg\n",
            "Downloaded2: cricbuzz_images2/week-1-batters-dominate-fing.jpg\n",
            "Downloaded2: cricbuzz_images2/the-world-cup-pulse.jpg\n",
            "Downloaded2: cricbuzz_images2/cricket-in-olympics-the-behin.jpg\n",
            "Downloaded2: cricbuzz_images2/why-the-odi-world-cup-will-end.jpg\n",
            "Downloaded2: cricbuzz_images2/american-premier-league-launch.jpg\n",
            "Downloaded2: cricbuzz_images2/sole-survivor-wesley-barresi.jpg\n",
            "Downloaded2: cricbuzz_images2/icc-confirms-new-york-as-venue.jpg\n",
            "Downloaded2: cricbuzz_images2/cricbuzz-live-world-cup-aus.jpg\n",
            "Downloaded2: cricbuzz_images2/olympics-needs-cricket-more-th.jpg\n",
            "Downloaded2: cricbuzz_images2/sri-lanka-lacked-scoreboard-aw.jpg\n",
            "Downloaded2: cricbuzz_images2/cb_logo.svg\n",
            "Images extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wEx4BpJQKV0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}